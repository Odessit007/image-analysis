{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from random import randint, seed\n",
    "import skimage.feature\n",
    "import skimage.io\n",
    "import sklearn.cluster\n",
    "import sklearn.svm\n",
    "\n",
    "%matplotlib inline\n",
    "seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['airplanes', 'ferry', 'laptop']\n",
    "label_names_dict = {'airplanes': 0, 'ferry': 1, 'laptop': 2}\n",
    "n_classes = len(label_names)\n",
    "n_train = 47\n",
    "n_test  = 20\n",
    "\n",
    "\n",
    "def read_caltech():\n",
    "    \"\"\"\n",
    "    Reads images from Caltech dataset (images of the same category must be in the same folder)\n",
    "    \"\"\"\n",
    "    path = './caltech-101/'\n",
    "    train_batch = {'data': [], 'labels': []}\n",
    "    test_batch = {'data': [], 'labels': []}\n",
    "\n",
    "    n_total = n_train + n_test\n",
    "    for label, label_ix in label_names_dict.items():\n",
    "        cnt = 0\n",
    "        PATH = path + label\n",
    "        for file in os.listdir(PATH):\n",
    "            cnt += 1\n",
    "            if cnt <= n_train:\n",
    "                train_batch['data'].append(cv2.imread(PATH + '/' + file))\n",
    "                train_batch['labels'].append(label_ix)\n",
    "            elif cnt <= n_total:\n",
    "                test_batch['data'].append(cv2.imread(PATH + '/' + file))\n",
    "                test_batch['labels'].append(label_ix)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    I_train = np.random.permutation(n_classes * n_train)\n",
    "    train_batch['data'] = np.array(train_batch['data'])[I_train]\n",
    "    train_batch['labels'] = np.array(train_batch['labels'])[I_train]\n",
    "    \n",
    "    I_test = np.random.permutation(n_classes * n_test)\n",
    "    test_batch['data'] = np.array(test_batch['data'])[I_test]\n",
    "    test_batch['labels'] = np.array(test_batch['labels'])[I_test]  \n",
    "    \n",
    "    return train_batch, test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch, test_batch = read_caltech()\n",
    "n_train *= n_classes\n",
    "n_test *= n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(img):\n",
    "    \"\"\"\n",
    "    Plots image with axis turned off.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(2, 2))\n",
    "    ax.imshow(img, interpolation='bicubic')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_examples(batch):\n",
    "    \"\"\"\n",
    "    Plots one example for each category\n",
    "    \"\"\"\n",
    "    def get_examples():\n",
    "        d = dict()\n",
    "        data = batch['data']\n",
    "        labels = batch['labels']\n",
    "        for img, label in zip(data, labels):\n",
    "            if len(d) == n_classes:\n",
    "                break\n",
    "            d[label] = img\n",
    "        return d\n",
    "    \n",
    "    examples = get_examples()\n",
    "    half = n_classes // 2\n",
    "    fig, ax = plt.subplots(half + 1, 2, figsize=(4, 3*half), subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i in range(n_classes):\n",
    "        ix = i // 2\n",
    "        jx = i % 2\n",
    "        ax[ix, jx].imshow(examples[i], interpolation='bicubic')\n",
    "        ax[ix, jx].set_title(label_names[i])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "show_examples(train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptors(img):\n",
    "    \"\"\"\n",
    "    Returns SIFT descriptors for given image\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    _, des = sift.detectAndCompute(gray, None)\n",
    "    return des\n",
    "\n",
    "\n",
    "def get_all_descriptors(batch):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    1) dictionary with keys - image numbers and values - sets of SIFT descriptors\n",
    "    2) list of all SIFT descriptors of all images)\n",
    "    \"\"\"\n",
    "    img2desc = {}\n",
    "    all_descriptors = []\n",
    "    n_img = len(batch['data'])\n",
    "    for i, img in enumerate(batch['data']):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print('{:.0f}%'.format(i / n_img * 100))\n",
    "        des = get_descriptors(img)\n",
    "        if des is None:\n",
    "            continue\n",
    "        img2desc[i] = des\n",
    "        if des.shape[0] >= 5:\n",
    "            for descriptor in des:\n",
    "                all_descriptors.append(descriptor)\n",
    "    print('{0} out of {1} images have at least 5 descriptors'.format(len(img2desc), n_img))\n",
    "    return img2desc, all_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "img2desc, all_descriptors = get_all_descriptors(train_batch)\n",
    "print('Total number of descriptors:', len(all_descriptors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_means(data, k):\n",
    "    \"\"\"\n",
    "    Creates MiniBatchKMeans object and clusters data in k groups\n",
    "    \"\"\"\n",
    "    kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=k, n_init=20, init_size=3*n_clusters).fit(data)\n",
    "    s = 'Clustering in {0} clusters took {1} iterations'\n",
    "    s = s.format(k, kmeans.n_iter_, kmeans.inertia_)\n",
    "    print(s)\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "def get_histogram(descriptors, kmeans):\n",
    "    \"\"\"\n",
    "    Builds histogram:\n",
    "        for each descriptor in descriptors we find the closest center among kmeans clusters\n",
    "        the set of centers is vocabulary\n",
    "        for each center we count the number of descriptors for which this center was chosen\n",
    "        these counts are the resulting histogram (aka bag-of-visual-words, aka bag-of-features)\n",
    "    \"\"\"\n",
    "    k = kmeans.n_clusters\n",
    "    hist = np.zeros(k)\n",
    "    words = kmeans.predict(descriptors)\n",
    "    for word in words:\n",
    "        hist[word] += 1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Here we get all descriptors for training dataset and perform the clustering\n",
    "print(\"I'm here\")\n",
    "\n",
    "n_clusters = 500\n",
    "all_descriptors = np.array(all_descriptors)\n",
    "kmeans = run_k_means(all_descriptors, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Here we create histograms for each image (unsing precomputed desctiptors stored in img2desc)\n",
    "print(\"I'm here\")\n",
    "\n",
    "n = len(img2desc)\n",
    "y_train = np.zeros(n)\n",
    "X_train = np.zeros((n, n_clusters))\n",
    "\n",
    "i = 0\n",
    "for img_ix, descriptors in img2desc.items():\n",
    "    X_train[i,:] = get_histogram(descriptors, kmeans)\n",
    "    y_train[i] = train_batch['labels'][img_ix]\n",
    "    i += 1\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Here we train the SVM classifier (samples are histograms, labels are classes)\n",
    "print(\"I'm here\")\n",
    "\n",
    "svm = sklearn.svm.SVC(gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_bad = 0\n",
    "\n",
    "\n",
    "def get_prediction(img, kmeans, svm):\n",
    "    \"\"\"\n",
    "    Get prediction for given image\n",
    "    \"\"\"\n",
    "    descriptors = get_descriptors(img)\n",
    "    if descriptors is None:\n",
    "        global cnt_bad\n",
    "        cnt_bad += 1\n",
    "        return randint(0, n_classes)\n",
    "    hist = get_histogram(descriptors, kmeans)\n",
    "    return svm.predict(hist.reshape(1, -1))\n",
    "\n",
    "\n",
    "def get_all_predictions(batch, kmeans, svm):\n",
    "    \"\"\"\n",
    "    Get prediction for all images in the batch and compute accuracy\n",
    "    \"\"\"\n",
    "    cnt_ok = 0\n",
    "    for img, true_label in zip(batch['data'], batch['labels']):\n",
    "        pred_label = get_prediction(img, kmeans, svm)\n",
    "        if pred_label == true_label:\n",
    "            cnt_ok += 1\n",
    "    n = len(batch['data'])\n",
    "    print('No descriptors were detected for {} images'.format(cnt_bad))\n",
    "    print('Accuracy: {:.2f}'.format(cnt_ok / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"I'm here\")\n",
    "\n",
    "get_all_predictions(test_batch, kmeans, svm)\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_random(kmeans, svm, i=None):\n",
    "    \"\"\"\n",
    "    Classifies random image from the test set\n",
    "    \"\"\"\n",
    "    if i is None:\n",
    "        i = randint(0, n_test-1)\n",
    "    img = test_batch['data'][i]\n",
    "    plot_sample(img)\n",
    "    label_pred = int(get_prediction(img, kmeans, svm))\n",
    "    print('I guess this is')\n",
    "    print(label_names[label_pred].upper())\n",
    "    print('Its real label is')\n",
    "    label_true = test_batch['labels'][i]\n",
    "    print(label_names[label_true].upper())\n",
    "\n",
    "\n",
    "classify_random(kmeans, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml36",
   "language": "python",
   "name": "ml36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
